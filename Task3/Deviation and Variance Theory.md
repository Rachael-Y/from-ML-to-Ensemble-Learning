Deviation and Variance Theory
## Task03：偏差方差理论

截图自《机器学习》周志华
公式推导待补充
萌神的拓展待消化与动手尝试后补充

上一篇中介绍了各类回归模型
本篇始，介绍下多种常见的评估方法和性能度量标准，以根据数据集以及模型任务的特征，选择出最合适的评估和性能度量方法来计算出学习器的“测试误差”。
但由于“测试误差”受到很多因素的影响，例如：算法随机性(例如常见的K-Means)或测试集本身的选择，使得同一模型每次得到的结果不尽相同；同时测试误差作为泛化误差的近似，并不能代表学习器真实的泛化性能，
那如何对单个或多个学习器在不同或相同测试集上的性能度量结果做比较呢？就需要通过“比较检验”。
此时，偏差与方差作为解释学习器泛化性能的一种重要工具，加以赘述。

##3.1 比较检验

在比较学习器泛化性能的过程中，统计假设检验（hypothesis test）为学习器性能比较提供了重要依据，即若A在某测试集上的性能优于B，则A学习器比B好的把握有多大。 
大部分博文中都是以“错误率”作为性能度量的标准。

###3.1.1 假设检验

“假设”指的是对样本总体的分布或已知分布中某个参数值的一种猜想，例如：假设总体服从泊松分布，或假设正态总体的期望u=U0。
通常情况下，我们可以通过测试获得测试错误率，不过直观上测试错误率和泛化错误率相差不会太远，因此可以通过测试错误率来推测泛化错误率的分布。


![728922097929a59c268401fc0c8b1fd](https://user-images.githubusercontent.com/62379948/112012417-26455300-8b64-11eb-99a2-b2def4446f6e.png)
![24f0cda424eb09af5d1254090d6c405](https://user-images.githubusercontent.com/62379948/112012452-2ba29d80-8b64-11eb-9a05-32259d75db91.png)

###3.1.2 交叉验证t检验
###3.1.3 McNemar检验
###3.1.4 Friedman检验与Nemenyi后续检验

3.2 偏差与方差

偏差-方差分解是解释学习器泛化性能的重要工具。在学习算法中，偏差指的是预测的期望值与真实值的偏差，方差则是每一次预测值与预测值得期望之间的差均方。
实际上，偏差体现了学习器预测的准确度，而方差体现了学习器预测的稳定性。
通过对泛化误差的进行分解，可得：

期望泛化误差=方差+偏差

其中：
偏差刻画学习器的拟合能力
方差体现学习器的稳定性

由上易知：方差和偏差具有矛盾性，即常说的偏差-方差窘境（bias-variance dilamma）。
随着训练程度的提升，期望预测值与真实值之间的差异越来越小，即偏差越来越小，但是另一方面，随着训练程度加大，学习算法对数据集的波动越来越敏感，方差值越来越大。
换句话说：在欠拟合时，偏差主导泛化误差，而训练到一定程度后，偏差越来越小，方差主导了泛化误差。
因此训练也不得贪杯，浅尝辄止。

![f9528648f42db987d60d1be2026d551](https://user-images.githubusercontent.com/62379948/112013264-e16dec00-8b64-11eb-80c9-5b5e03d361a5.png)
